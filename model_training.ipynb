{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fcff3317",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84abc3b3",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b901a98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"Data/Preprocessed/1-train-clean.csv\")\n",
    "val = pd.read_csv(\"Data/Preprocessed/2-val-clean.csv\")\n",
    "test = pd.read_csv(\"Data/Preprocessed/3-test-clean.csv\")\n",
    "\n",
    "X_train = train['review_clean'].tolist()\n",
    "y_train = train.drop(columns=['review_clean'])\n",
    "\n",
    "X_val = val['review_clean'].tolist()\n",
    "y_val = val.drop(columns=['review_clean'])\n",
    "\n",
    "X_test = test['review_clean'].tolist()\n",
    "y_test = test.drop(columns=['review_clean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "205603da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random_indices = random.sample(list(y_train.index), 4)\n",
    "\n",
    "y_train.loc[random_indices[0], 'food&drinks#miscellaneous'] = 1\n",
    "y_train.loc[random_indices[1], 'room_amenities#miscellaneous'] = 1\n",
    "y_train.loc[random_indices[2], 'rooms#miscellaneous'] = 1\n",
    "y_train.loc[random_indices[3], 'room_amenities#prices'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c20a51",
   "metadata": {},
   "source": [
    "# Score Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db769441",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, classification_report\n",
    "\n",
    "# Chuyển ma trận (N, K) thành ma trận nhị phân (N, 3*K) để tính F1-score\n",
    "def multioutput_to_multilabel(y_sentiment_indices):\n",
    "    if isinstance(y_sentiment_indices, pd.DataFrame):\n",
    "        y_sentiment_indices = y_sentiment_indices.values\n",
    "\n",
    "    nrow = y_sentiment_indices.shape[0] # Số lượng mẫu.\n",
    "    ncol = y_sentiment_indices.shape[1] # Số lượng aspect.\n",
    "\n",
    "    # Khởi tạo mảng Multi-label (Boolean) với kích thước: Hàng x (3 * Cột).\n",
    "    multilabel = np.zeros((nrow, 3 * ncol), dtype=bool)\n",
    "    for i in range(nrow):\n",
    "        for j in range(ncol):\n",
    "            sentiment_idx = y_sentiment_indices[i, j]\n",
    "            if sentiment_idx != 0:\n",
    "                pos = j * 3 + (sentiment_idx - 1)\n",
    "                multilabel[i, pos] = True\n",
    "    return multilabel\n",
    "\n",
    "# Tính F1-score dựa trên ma trận nhị phân\n",
    "def custom_f1_score(y_true, y_pred, average='micro', **kwargs):\n",
    "    y_true_ml = multioutput_to_multilabel(y_true)\n",
    "    y_pred_ml = multioutput_to_multilabel(y_pred)\n",
    "    return round(f1_score(y_true_ml, y_pred_ml, average=average, **kwargs), 4)\n",
    "\n",
    "# Tạo báo cáo phân loại dựa trên ma trận nhị phân\n",
    "def custom_classification_report(y_true, y_pred, **kwargs):\n",
    "    y_true_ml = multioutput_to_multilabel(y_true)\n",
    "    y_pred_ml = multioutput_to_multilabel(y_pred)\n",
    "    return classification_report(y_true_ml, y_pred_ml, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e8d57d",
   "metadata": {},
   "source": [
    "# **Machine Learning Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195af192",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2140a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 3), min_df=2, max_df=0.9)\n",
    "\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_val_tfidf = vectorizer.transform(X_val)\n",
    "X_test_tfidf = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "32fad3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multioutput import MultiOutputClassifier as MOC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5a8afb",
   "metadata": {},
   "source": [
    "## PhoW2V Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2e2f3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_phow2v = pd.read_csv('Data/Embedding/1-train-phoW2V.csv')\n",
    "val_phow2v = pd.read_csv('Data/Embedding/2-val-phoW2V.csv')\n",
    "test_phow2v = pd.read_csv('Data/Embedding/3-test-phoW2V.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "72e1e9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_phow2v = train_phow2v.iloc[:, :100]\n",
    "X_val_phow2v = val_phow2v.iloc[:, :100]\n",
    "X_test_phow2v = test_phow2v.iloc[:, :100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf28ec1",
   "metadata": {},
   "source": [
    "## Search Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c88bc40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\DS102\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from optuna.samplers import TPESampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab83884",
   "metadata": {},
   "outputs": [],
   "source": [
    "def callback(study, trial):\n",
    "    if study.best_trial.number == trial.number:\n",
    "        study.set_user_attr(key='best_model', value=trial.user_attrs['model'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c672b5",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b2e63042",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c542bf23",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5682387a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-19 16:50:59,358] A new study created in memory with name: no-name-0aee7318-2a58-4a40-a941-28220fd7f967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-19 16:51:05,287] Trial 0 finished with value: 0.6669 and parameters: {'class_weight': None, 'C': 8.41076650090714}. Best is trial 0 with value: 0.6669.\n",
      "[I 2025-12-19 16:51:10,152] Trial 1 finished with value: 0.6882 and parameters: {'class_weight': 'balanced', 'C': 6.777285823434402}. Best is trial 1 with value: 0.6882.\n",
      "[I 2025-12-19 16:51:15,723] Trial 2 finished with value: 0.6626 and parameters: {'class_weight': None, 'C': 4.408098128709346}. Best is trial 1 with value: 0.6882.\n",
      "[I 2025-12-19 16:51:20,192] Trial 3 finished with value: 0.6864 and parameters: {'class_weight': 'balanced', 'C': 11.224078321223027}. Best is trial 1 with value: 0.6882.\n",
      "[I 2025-12-19 16:51:24,697] Trial 4 finished with value: 0.6845 and parameters: {'class_weight': 'balanced', 'C': 3.7822352140976876}. Best is trial 1 with value: 0.6882.\n",
      "[I 2025-12-19 16:51:30,464] Trial 5 finished with value: 0.6709 and parameters: {'class_weight': None, 'C': 19.156643783543824}. Best is trial 1 with value: 0.6882.\n",
      "[I 2025-12-19 16:51:35,931] Trial 6 finished with value: 0.6845 and parameters: {'class_weight': 'balanced', 'C': 15.3598571591844}. Best is trial 1 with value: 0.6882.\n",
      "[I 2025-12-19 16:51:41,536] Trial 7 finished with value: 0.6868 and parameters: {'class_weight': 'balanced', 'C': 12.304120349802874}. Best is trial 1 with value: 0.6882.\n",
      "[I 2025-12-19 16:51:47,912] Trial 8 finished with value: 0.6704 and parameters: {'class_weight': None, 'C': 14.05271335095385}. Best is trial 1 with value: 0.6882.\n",
      "[I 2025-12-19 16:51:53,949] Trial 9 finished with value: 0.6704 and parameters: {'class_weight': None, 'C': 19.777725588403577}. Best is trial 1 with value: 0.6882.\n",
      "[I 2025-12-19 16:51:58,222] Trial 10 finished with value: 0.671 and parameters: {'class_weight': 'balanced', 'C': 0.5107159072096135}. Best is trial 1 with value: 0.6882.\n",
      "[I 2025-12-19 16:52:03,107] Trial 11 finished with value: 0.6879 and parameters: {'class_weight': 'balanced', 'C': 7.762883386853096}. Best is trial 1 with value: 0.6882.\n",
      "[I 2025-12-19 16:52:07,948] Trial 12 finished with value: 0.6863 and parameters: {'class_weight': 'balanced', 'C': 7.529806648038684}. Best is trial 1 with value: 0.6882.\n",
      "[I 2025-12-19 16:52:12,384] Trial 13 finished with value: 0.687 and parameters: {'class_weight': 'balanced', 'C': 5.932335159783881}. Best is trial 1 with value: 0.6882.\n",
      "[I 2025-12-19 16:52:16,597] Trial 14 finished with value: 0.6751 and parameters: {'class_weight': 'balanced', 'C': 0.6701430694272572}. Best is trial 1 with value: 0.6882.\n",
      "[I 2025-12-19 16:52:21,438] Trial 15 finished with value: 0.6854 and parameters: {'class_weight': 'balanced', 'C': 9.460256307464324}. Best is trial 1 with value: 0.6882.\n",
      "[I 2025-12-19 16:52:26,101] Trial 16 finished with value: 0.6847 and parameters: {'class_weight': 'balanced', 'C': 3.6695343570131618}. Best is trial 1 with value: 0.6882.\n",
      "[I 2025-12-19 16:52:31,309] Trial 17 finished with value: 0.687 and parameters: {'class_weight': 'balanced', 'C': 6.5601630317969075}. Best is trial 1 with value: 0.6882.\n",
      "[I 2025-12-19 16:52:35,906] Trial 18 finished with value: 0.6861 and parameters: {'class_weight': 'balanced', 'C': 10.96845695217124}. Best is trial 1 with value: 0.6882.\n",
      "[I 2025-12-19 16:52:40,490] Trial 19 finished with value: 0.6826 and parameters: {'class_weight': 'balanced', 'C': 2.5069472913454307}. Best is trial 1 with value: 0.6882.\n"
     ]
    }
   ],
   "source": [
    "def logistic_objective(trial):\n",
    "    params = dict(\n",
    "        class_weight=trial.suggest_categorical('class_weight', ['balanced', None]),\n",
    "        C=trial.suggest_float('C', 1e-5, 20),\n",
    "        random_state=42,\n",
    "        max_iter=200\n",
    "    )    \n",
    "\n",
    "    clf = MOC(LogisticRegression(**params))\n",
    "    clf.fit(X_train_tfidf, y_train)\n",
    "    trial.set_user_attr(key=\"model\", value=clf)\n",
    "\n",
    "    y_pred = clf.predict(X_val_tfidf)\n",
    "    return custom_f1_score(y_val, y_pred)\n",
    "\n",
    "sampler = TPESampler(seed=22)\n",
    "logistic_study = optuna.create_study(sampler=sampler, direction='maximize')\n",
    "logistic_study.optimize(logistic_objective, n_trials=20, callbacks=[callback])\n",
    "\n",
    "lgr = logistic_study.user_attrs['best_model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7c3ca1a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression with Best Hyperparameters F1-scores:\n",
      "train: 0.9962\n",
      "val:   0.6882\n",
      "test:  0.7033\n",
      "{'C': 6.777285823434402, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 200, 'multi_class': 'deprecated', 'n_jobs': None, 'penalty': 'l2', 'random_state': 42, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "Best hyperparameters:\n",
      "{'class_weight': 'balanced', 'C': 6.777285823434402}\n"
     ]
    }
   ],
   "source": [
    "print(\"Logistic Regression with Best Hyperparameters F1-scores:\")\n",
    "print('train:', custom_f1_score(y_train, lgr.predict(X_train_tfidf)))\n",
    "print('val:  ', custom_f1_score(y_val  , lgr.predict(X_val_tfidf)))\n",
    "print('test: ', custom_f1_score(y_test , lgr.predict(X_test_tfidf)))\n",
    "\n",
    "print(lgr.estimators_[0].get_params())\n",
    "print(\"\\nBest hyperparameters:\")\n",
    "print(logistic_study.best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7cfe664",
   "metadata": {},
   "source": [
    "### PhoW2V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2e598b5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-19 16:53:59,949] A new study created in memory with name: no-name-3daacf80-1436-4b5f-8eb6-1fc20e89ffb9\n",
      "[I 2025-12-19 16:54:00,694] Trial 0 finished with value: 0.625 and parameters: {'class_weight': None, 'C': 8.41076650090714}. Best is trial 0 with value: 0.625.\n",
      "[I 2025-12-19 16:54:01,781] Trial 1 finished with value: 0.4352 and parameters: {'class_weight': 'balanced', 'C': 6.777285823434402}. Best is trial 0 with value: 0.625.\n",
      "[I 2025-12-19 16:54:02,366] Trial 2 finished with value: 0.6136 and parameters: {'class_weight': None, 'C': 4.408098128709346}. Best is trial 0 with value: 0.625.\n",
      "[I 2025-12-19 16:54:03,630] Trial 3 finished with value: 0.4562 and parameters: {'class_weight': 'balanced', 'C': 11.224078321223027}. Best is trial 0 with value: 0.625.\n",
      "[I 2025-12-19 16:54:04,657] Trial 4 finished with value: 0.4087 and parameters: {'class_weight': 'balanced', 'C': 3.7822352140976876}. Best is trial 0 with value: 0.625.\n",
      "[I 2025-12-19 16:54:05,446] Trial 5 finished with value: 0.6363 and parameters: {'class_weight': None, 'C': 19.156643783543824}. Best is trial 5 with value: 0.6363.\n",
      "[I 2025-12-19 16:54:06,769] Trial 6 finished with value: 0.4643 and parameters: {'class_weight': 'balanced', 'C': 15.3598571591844}. Best is trial 5 with value: 0.6363.\n",
      "[I 2025-12-19 16:54:08,023] Trial 7 finished with value: 0.4591 and parameters: {'class_weight': 'balanced', 'C': 12.304120349802874}. Best is trial 5 with value: 0.6363.\n",
      "[I 2025-12-19 16:54:08,769] Trial 8 finished with value: 0.6334 and parameters: {'class_weight': None, 'C': 14.05271335095385}. Best is trial 5 with value: 0.6363.\n",
      "[I 2025-12-19 16:54:09,477] Trial 9 finished with value: 0.6362 and parameters: {'class_weight': None, 'C': 19.777725588403577}. Best is trial 5 with value: 0.6363.\n",
      "[I 2025-12-19 16:54:10,266] Trial 10 finished with value: 0.6342 and parameters: {'class_weight': None, 'C': 19.991902708535964}. Best is trial 5 with value: 0.6363.\n",
      "[I 2025-12-19 16:54:11,027] Trial 11 finished with value: 0.6347 and parameters: {'class_weight': None, 'C': 19.977618938641324}. Best is trial 5 with value: 0.6363.\n",
      "[I 2025-12-19 16:54:11,814] Trial 12 finished with value: 0.6347 and parameters: {'class_weight': None, 'C': 17.296630328925062}. Best is trial 5 with value: 0.6363.\n",
      "[I 2025-12-19 16:54:12,621] Trial 13 finished with value: 0.6337 and parameters: {'class_weight': None, 'C': 16.910726817690954}. Best is trial 5 with value: 0.6363.\n",
      "[I 2025-12-19 16:54:13,142] Trial 14 finished with value: 0.5816 and parameters: {'class_weight': None, 'C': 0.3089718596821598}. Best is trial 5 with value: 0.6363.\n",
      "[I 2025-12-19 16:54:14,010] Trial 15 finished with value: 0.6342 and parameters: {'class_weight': None, 'C': 17.939293427417454}. Best is trial 5 with value: 0.6363.\n",
      "[I 2025-12-19 16:54:14,749] Trial 16 finished with value: 0.6331 and parameters: {'class_weight': None, 'C': 13.887627016105206}. Best is trial 5 with value: 0.6363.\n",
      "[I 2025-12-19 16:54:15,529] Trial 17 finished with value: 0.6349 and parameters: {'class_weight': None, 'C': 18.31400640387008}. Best is trial 5 with value: 0.6363.\n",
      "[I 2025-12-19 16:54:16,273] Trial 18 finished with value: 0.6347 and parameters: {'class_weight': None, 'C': 15.588768704102371}. Best is trial 5 with value: 0.6363.\n",
      "[I 2025-12-19 16:54:16,982] Trial 19 finished with value: 0.633 and parameters: {'class_weight': None, 'C': 12.856895417259325}. Best is trial 5 with value: 0.6363.\n"
     ]
    }
   ],
   "source": [
    "def logistic_objective(trial):\n",
    "    params = dict(\n",
    "        class_weight=trial.suggest_categorical('class_weight', ['balanced', None]),\n",
    "        C=trial.suggest_float('C', 1e-5, 20),\n",
    "        random_state=42,\n",
    "        max_iter=200\n",
    "    )    \n",
    "\n",
    "    clf = MOC(LogisticRegression(**params))\n",
    "    clf.fit(X_train_phow2v, y_train)\n",
    "    trial.set_user_attr(key=\"model\", value=clf)\n",
    "\n",
    "    y_pred = clf.predict(X_val_phow2v)\n",
    "    return custom_f1_score(y_val, y_pred)\n",
    "\n",
    "sampler = TPESampler(seed=22)\n",
    "logistic_study = optuna.create_study(sampler=sampler, direction='maximize')\n",
    "logistic_study.optimize(logistic_objective, n_trials=20, callbacks=[callback])\n",
    "\n",
    "lgr = logistic_study.user_attrs['best_model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e598180e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression with Best Hyperparameters F1-scores:\n",
      "train: 0.6898\n",
      "val:   0.6363\n",
      "test:  0.6525\n",
      "{'C': 19.156643783543824, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 200, 'multi_class': 'deprecated', 'n_jobs': None, 'penalty': 'l2', 'random_state': 42, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "Best hyperparameters:\n",
      "{'class_weight': None, 'C': 19.156643783543824}\n"
     ]
    }
   ],
   "source": [
    "print(\"Logistic Regression with Best Hyperparameters F1-scores:\")\n",
    "print('train:', custom_f1_score(y_train, lgr.predict(X_train_phow2v)))\n",
    "print('val:  ', custom_f1_score(y_val  , lgr.predict(X_val_phow2v)))\n",
    "print('test: ', custom_f1_score(y_test , lgr.predict(X_test_phow2v)))\n",
    "\n",
    "print(lgr.estimators_[0].get_params())\n",
    "print(\"\\nBest hyperparameters:\")\n",
    "print(logistic_study.best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3fe96e",
   "metadata": {},
   "source": [
    "## Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "33a3822c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c38ac9",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0463f398",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-19 15:40:07,661] A new study created in memory with name: no-name-edd6881a-ab5e-4fe5-a78d-75befb4cd290\n",
      "[I 2025-12-19 15:40:07,911] Trial 0 finished with value: 0.4441 and parameters: {'C': 1.9636582699290402e-07, 'class_weight': 'balanced', 'loss': 'hinge'}. Best is trial 0 with value: 0.4441.\n",
      "[I 2025-12-19 15:40:08,166] Trial 1 finished with value: 0.5715 and parameters: {'C': 5.339536586472381e-06, 'class_weight': None, 'loss': 'squared_hinge'}. Best is trial 1 with value: 0.5715.\n",
      "[I 2025-12-19 15:40:08,341] Trial 2 finished with value: 0.5715 and parameters: {'C': 1.3055563380836963e-09, 'class_weight': None, 'loss': 'hinge'}. Best is trial 1 with value: 0.5715.\n",
      "[I 2025-12-19 15:40:08,518] Trial 3 finished with value: 0.5715 and parameters: {'C': 1.1682869614143264e-09, 'class_weight': None, 'loss': 'hinge'}. Best is trial 1 with value: 0.5715.\n",
      "[I 2025-12-19 15:40:08,911] Trial 4 finished with value: 0.6397 and parameters: {'C': 0.2804917948703948, 'class_weight': 'balanced', 'loss': 'hinge'}. Best is trial 4 with value: 0.6397.\n",
      "[I 2025-12-19 15:40:09,291] Trial 5 finished with value: 0.5715 and parameters: {'C': 0.002674151911363306, 'class_weight': 'balanced', 'loss': 'squared_hinge'}. Best is trial 4 with value: 0.6397.\n",
      "[I 2025-12-19 15:40:09,740] Trial 6 finished with value: 0.5961 and parameters: {'C': 0.02828254640470946, 'class_weight': 'balanced', 'loss': 'squared_hinge'}. Best is trial 4 with value: 0.6397.\n",
      "[I 2025-12-19 15:40:10,207] Trial 7 finished with value: 0.6557 and parameters: {'C': 0.15640579894830894, 'class_weight': 'balanced', 'loss': 'squared_hinge'}. Best is trial 7 with value: 0.6557.\n",
      "[I 2025-12-19 15:40:10,407] Trial 8 finished with value: 0.5715 and parameters: {'C': 2.6540634283127564e-06, 'class_weight': None, 'loss': 'hinge'}. Best is trial 7 with value: 0.6557.\n",
      "[I 2025-12-19 15:40:10,865] Trial 9 finished with value: 0.6023 and parameters: {'C': 0.03412839819879307, 'class_weight': 'balanced', 'loss': 'squared_hinge'}. Best is trial 7 with value: 0.6557.\n",
      "[I 2025-12-19 15:40:17,337] Trial 10 finished with value: 0.677 and parameters: {'C': 78.77092791878185, 'class_weight': 'balanced', 'loss': 'squared_hinge'}. Best is trial 10 with value: 0.677.\n",
      "[I 2025-12-19 15:40:25,170] Trial 11 finished with value: 0.677 and parameters: {'C': 95.8756355602386, 'class_weight': 'balanced', 'loss': 'squared_hinge'}. Best is trial 10 with value: 0.677.\n",
      "[I 2025-12-19 15:40:32,607] Trial 12 finished with value: 0.677 and parameters: {'C': 87.24268909156903, 'class_weight': 'balanced', 'loss': 'squared_hinge'}. Best is trial 10 with value: 0.677.\n",
      "[I 2025-12-19 15:40:40,469] Trial 13 finished with value: 0.677 and parameters: {'C': 92.27087648045014, 'class_weight': 'balanced', 'loss': 'squared_hinge'}. Best is trial 10 with value: 0.677.\n",
      "[I 2025-12-19 15:40:41,456] Trial 14 finished with value: 0.6792 and parameters: {'C': 4.625128187286929, 'class_weight': 'balanced', 'loss': 'squared_hinge'}. Best is trial 14 with value: 0.6792.\n",
      "[I 2025-12-19 15:40:42,175] Trial 15 finished with value: 0.6804 and parameters: {'C': 2.1641891327172247, 'class_weight': 'balanced', 'loss': 'squared_hinge'}. Best is trial 15 with value: 0.6804.\n",
      "[I 2025-12-19 15:40:42,804] Trial 16 finished with value: 0.6827 and parameters: {'C': 1.4791962969452819, 'class_weight': 'balanced', 'loss': 'squared_hinge'}. Best is trial 16 with value: 0.6827.\n",
      "[I 2025-12-19 15:40:43,148] Trial 17 finished with value: 0.5672 and parameters: {'C': 0.00017330719324443333, 'class_weight': 'balanced', 'loss': 'squared_hinge'}. Best is trial 16 with value: 0.6827.\n",
      "[I 2025-12-19 15:40:43,803] Trial 18 finished with value: 0.6775 and parameters: {'C': 1.8959557425289035, 'class_weight': None, 'loss': 'squared_hinge'}. Best is trial 16 with value: 0.6827.\n",
      "[I 2025-12-19 15:40:44,187] Trial 19 finished with value: 0.5721 and parameters: {'C': 0.0014070627356621709, 'class_weight': 'balanced', 'loss': 'squared_hinge'}. Best is trial 16 with value: 0.6827.\n"
     ]
    }
   ],
   "source": [
    "def linearsvc_objective(trial):\n",
    "    params = dict(\n",
    "        C=trial.suggest_float('C', 1e-9, 1e2, log=True),\n",
    "        class_weight=trial.suggest_categorical('class_weight', ['balanced', None]),\n",
    "        loss=trial.suggest_categorical('loss', ['hinge', 'squared_hinge']),\n",
    "        max_iter=10000,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    if params['loss'] == 'hinge':\n",
    "        params['dual'] = True\n",
    "    clf = MOC(LinearSVC(**params))\n",
    "    clf.fit(X_train_tfidf, y_train)\n",
    "    trial.set_user_attr(key=\"model\", value=clf)\n",
    "    \n",
    "    y_pred = clf.predict(X_val_tfidf)\n",
    "    return custom_f1_score(y_val, y_pred)\n",
    "\n",
    "sampler = TPESampler(seed=22)\n",
    "svc_study = optuna.create_study(sampler=sampler, direction='maximize')\n",
    "svc_study.optimize(linearsvc_objective, n_trials=20, callbacks=[callback])\n",
    "\n",
    "svc_linear = svc_study.user_attrs['best_model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6404d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVC with Best Hyperparameters F1-scores:\n",
      "train: 0.9994\n",
      "dev:   0.6827\n",
      "test:  0.7016\n",
      "{'C': 1.4791962969452819, 'class_weight': 'balanced', 'dual': 'auto', 'fit_intercept': True, 'intercept_scaling': 1, 'loss': 'squared_hinge', 'max_iter': 10000, 'multi_class': 'ovr', 'penalty': 'l2', 'random_state': 42, 'tol': 0.0001, 'verbose': 0}\n",
      "\n",
      "Best hyperparameters:\n",
      "{'C': 1.4791962969452819, 'class_weight': 'balanced', 'loss': 'squared_hinge'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Linear SVC with Best Hyperparameters F1-scores:\")\n",
    "print('train:', custom_f1_score(y_train, svc_linear.predict(X_train_tfidf)))\n",
    "print('val:  ', custom_f1_score(y_val  , svc_linear.predict(X_val_tfidf)))\n",
    "print('test: ', custom_f1_score(y_test , svc_linear.predict(X_test_tfidf)))\n",
    "\n",
    "print(svc_linear.estimators_[0].get_params())\n",
    "print(\"\\nBest hyperparameters:\")\n",
    "print(svc_study.best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aacfb0fe",
   "metadata": {},
   "source": [
    "### PhoW2V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3926e12a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-19 16:55:58,061] A new study created in memory with name: no-name-cb389845-820a-4d9e-ac47-d71939ef6e24\n",
      "[I 2025-12-19 16:55:58,375] Trial 0 finished with value: 0.4066 and parameters: {'C': 1.9636582699290402e-07, 'class_weight': 'balanced', 'loss': 'hinge'}. Best is trial 0 with value: 0.4066.\n",
      "[I 2025-12-19 16:55:58,718] Trial 1 finished with value: 0.5715 and parameters: {'C': 5.339536586472381e-06, 'class_weight': None, 'loss': 'squared_hinge'}. Best is trial 1 with value: 0.5715.\n",
      "[I 2025-12-19 16:55:58,963] Trial 2 finished with value: 0.5715 and parameters: {'C': 1.3055563380836963e-09, 'class_weight': None, 'loss': 'hinge'}. Best is trial 1 with value: 0.5715.\n",
      "[I 2025-12-19 16:55:59,213] Trial 3 finished with value: 0.5715 and parameters: {'C': 1.1682869614143264e-09, 'class_weight': None, 'loss': 'hinge'}. Best is trial 1 with value: 0.5715.\n",
      "[I 2025-12-19 16:56:01,277] Trial 4 finished with value: 0.4732 and parameters: {'C': 0.2804917948703948, 'class_weight': 'balanced', 'loss': 'hinge'}. Best is trial 1 with value: 0.5715.\n",
      "[I 2025-12-19 16:56:01,831] Trial 5 finished with value: 0.5316 and parameters: {'C': 0.002674151911363306, 'class_weight': 'balanced', 'loss': 'squared_hinge'}. Best is trial 1 with value: 0.5715.\n",
      "[I 2025-12-19 16:56:02,561] Trial 6 finished with value: 0.5523 and parameters: {'C': 0.02828254640470946, 'class_weight': 'balanced', 'loss': 'squared_hinge'}. Best is trial 1 with value: 0.5715.\n",
      "[I 2025-12-19 16:56:03,450] Trial 7 finished with value: 0.5757 and parameters: {'C': 0.15640579894830894, 'class_weight': 'balanced', 'loss': 'squared_hinge'}. Best is trial 7 with value: 0.5757.\n",
      "[I 2025-12-19 16:56:03,719] Trial 8 finished with value: 0.5715 and parameters: {'C': 2.6540634283127564e-06, 'class_weight': None, 'loss': 'hinge'}. Best is trial 7 with value: 0.5757.\n",
      "[I 2025-12-19 16:56:04,457] Trial 9 finished with value: 0.5535 and parameters: {'C': 0.03412839819879307, 'class_weight': 'balanced', 'loss': 'squared_hinge'}. Best is trial 7 with value: 0.5757.\n",
      "[I 2025-12-19 16:56:06,107] Trial 10 finished with value: 0.6411 and parameters: {'C': 78.77092791878185, 'class_weight': 'balanced', 'loss': 'squared_hinge'}. Best is trial 10 with value: 0.6411.\n",
      "[I 2025-12-19 16:56:07,649] Trial 11 finished with value: 0.6408 and parameters: {'C': 95.8756355602386, 'class_weight': 'balanced', 'loss': 'squared_hinge'}. Best is trial 10 with value: 0.6411.\n",
      "[I 2025-12-19 16:56:09,277] Trial 12 finished with value: 0.6394 and parameters: {'C': 87.24268909156903, 'class_weight': 'balanced', 'loss': 'squared_hinge'}. Best is trial 10 with value: 0.6411.\n",
      "[I 2025-12-19 16:56:10,928] Trial 13 finished with value: 0.6401 and parameters: {'C': 92.27087648045014, 'class_weight': 'balanced', 'loss': 'squared_hinge'}. Best is trial 10 with value: 0.6411.\n",
      "[I 2025-12-19 16:56:12,162] Trial 14 finished with value: 0.6321 and parameters: {'C': 4.625128187286929, 'class_weight': 'balanced', 'loss': 'squared_hinge'}. Best is trial 10 with value: 0.6411.\n",
      "[I 2025-12-19 16:56:13,379] Trial 15 finished with value: 0.6268 and parameters: {'C': 2.255468473990366, 'class_weight': 'balanced', 'loss': 'squared_hinge'}. Best is trial 10 with value: 0.6411.\n",
      "[I 2025-12-19 16:56:14,716] Trial 16 finished with value: 0.6302 and parameters: {'C': 5.754895726691162, 'class_weight': 'balanced', 'loss': 'squared_hinge'}. Best is trial 10 with value: 0.6411.\n",
      "[I 2025-12-19 16:56:15,228] Trial 17 finished with value: 0.4275 and parameters: {'C': 0.00017330719324443333, 'class_weight': 'balanced', 'loss': 'squared_hinge'}. Best is trial 10 with value: 0.6411.\n",
      "[I 2025-12-19 16:56:15,726] Trial 18 finished with value: 0.5715 and parameters: {'C': 0.0004748395299999667, 'class_weight': None, 'loss': 'squared_hinge'}. Best is trial 10 with value: 0.6411.\n",
      "[I 2025-12-19 16:56:17,274] Trial 19 finished with value: 0.6369 and parameters: {'C': 14.830896676363363, 'class_weight': 'balanced', 'loss': 'squared_hinge'}. Best is trial 10 with value: 0.6411.\n"
     ]
    }
   ],
   "source": [
    "def linearsvc_objective(trial):\n",
    "    params = dict(\n",
    "        C=trial.suggest_float('C', 1e-9, 1e2, log=True),\n",
    "        class_weight=trial.suggest_categorical('class_weight', ['balanced', None]),\n",
    "        loss=trial.suggest_categorical('loss', ['hinge', 'squared_hinge']),\n",
    "        max_iter=10000,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    if params['loss'] == 'hinge':\n",
    "        params['dual'] = True\n",
    "    clf = MOC(LinearSVC(**params))\n",
    "    clf.fit(X_train_phow2v, y_train)\n",
    "    trial.set_user_attr(key=\"model\", value=clf)\n",
    "    \n",
    "    y_pred = clf.predict(X_val_phow2v)\n",
    "    return custom_f1_score(y_val, y_pred)\n",
    "sampler = TPESampler(seed=22)\n",
    "svc_study = optuna.create_study(sampler=sampler, direction='maximize')\n",
    "svc_study.optimize(linearsvc_objective, n_trials=20, callbacks=[callback])\n",
    "\n",
    "svc_linear = svc_study.user_attrs['best_model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "15023dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVC with Best Hyperparameters F1-scores:\n",
      "train: 0.745\n",
      "val:   0.6411\n",
      "test:  0.6432\n",
      "{'C': 78.77092791878185, 'class_weight': 'balanced', 'dual': 'auto', 'fit_intercept': True, 'intercept_scaling': 1, 'loss': 'squared_hinge', 'max_iter': 10000, 'multi_class': 'ovr', 'penalty': 'l2', 'random_state': 42, 'tol': 0.0001, 'verbose': 0}\n",
      "\n",
      "Best hyperparameters:\n",
      "{'C': 78.77092791878185, 'class_weight': 'balanced', 'loss': 'squared_hinge'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Linear SVC with Best Hyperparameters F1-scores:\")\n",
    "print('train:', custom_f1_score(y_train, svc_linear.predict(X_train_phow2v)))\n",
    "print('val:  ', custom_f1_score(y_val  , svc_linear.predict(X_val_phow2v)))\n",
    "print('test: ', custom_f1_score(y_test , svc_linear.predict(X_test_phow2v)))\n",
    "\n",
    "print(svc_linear.estimators_[0].get_params())\n",
    "print(\"\\nBest hyperparameters:\")\n",
    "print(svc_study.best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28969ee8",
   "metadata": {},
   "source": [
    "## Non-Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f7caf07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d91e0c",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036f6e86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-19 15:56:13,649] A new study created in memory with name: no-name-36960476-171d-4d5c-ae07-8dfe26928a20\n",
      "[I 2025-12-19 15:56:22,502] Trial 0 finished with value: 0.5715 and parameters: {'kernel': 'poly', 'C': 19.765599562374707, 'gamma': 'auto', 'class_weight': None, 'degree': 2}. Best is trial 0 with value: 0.5715.\n",
      "[I 2025-12-19 15:57:16,970] Trial 1 finished with value: 0.6436 and parameters: {'kernel': 'rbf', 'C': 11.71199658483352, 'gamma': 'scale', 'class_weight': None}. Best is trial 1 with value: 0.6436.\n",
      "[I 2025-12-19 15:58:24,242] Trial 2 finished with value: 0.6447 and parameters: {'kernel': 'rbf', 'C': 6.9177316302209935, 'gamma': 'scale', 'class_weight': 'balanced'}. Best is trial 2 with value: 0.6447.\n",
      "[I 2025-12-19 15:59:40,218] Trial 3 finished with value: 0.5933 and parameters: {'kernel': 'poly', 'C': 41.338016019468874, 'gamma': 'scale', 'class_weight': 'balanced', 'degree': 2}. Best is trial 2 with value: 0.6447.\n",
      "[I 2025-12-19 16:01:22,751] Trial 4 finished with value: 0.0358 and parameters: {'kernel': 'rbf', 'C': 0.0043819711016756845, 'gamma': 'auto', 'class_weight': 'balanced'}. Best is trial 2 with value: 0.6447.\n"
     ]
    }
   ],
   "source": [
    "def nonlinear_svc_objective(trial):\n",
    "    kernel_choice = trial.suggest_categorical('kernel', ['rbf', 'poly', 'sigmoid'])\n",
    "    \n",
    "    params = dict(\n",
    "        C=trial.suggest_float('C', 1e-3, 100, log=True),\n",
    "        kernel=kernel_choice,\n",
    "        gamma=trial.suggest_categorical('gamma', ['scale', 'auto']), \n",
    "        class_weight=trial.suggest_categorical('class_weight', ['balanced', None]),\n",
    "        random_state=42,\n",
    "        max_iter=10000 \n",
    "    )\n",
    "    \n",
    "    if kernel_choice == 'poly':\n",
    "        params['degree'] = trial.suggest_int('degree', 2, 4)\n",
    "\n",
    "    clf = MOC(SVC(**params))\n",
    "    clf.fit(X_train_tfidf, y_train)\n",
    "    trial.set_user_attr(key=\"model\", value=clf)\n",
    "\n",
    "    y_pred = clf.predict(X_val_tfidf)\n",
    "    return custom_f1_score(y_val, y_pred)\n",
    "\n",
    "sampler = TPESampler(seed=22)\n",
    "svc_nonlinear_study = optuna.create_study(sampler=sampler, direction='maximize')\n",
    "svc_nonlinear_study.optimize(nonlinear_svc_objective, n_trials=5, callbacks=[callback])\n",
    "\n",
    "nonlinear_svc = svc_nonlinear_study.user_attrs['best_model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b719cc2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-Linear SVC with Best Hyperparameters F1-scores:\n",
      "train: 0.9996\n",
      "dev:   0.6447\n",
      "test:  0.6595\n",
      "{'C': 6.9177316302209935, 'break_ties': False, 'cache_size': 200, 'class_weight': 'balanced', 'coef0': 0.0, 'decision_function_shape': 'ovr', 'degree': 3, 'gamma': 'scale', 'kernel': 'rbf', 'max_iter': 10000, 'probability': False, 'random_state': 42, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n",
      "\n",
      "Best hyperparameters:\n",
      "{'kernel': 'rbf', 'C': 6.9177316302209935, 'gamma': 'scale', 'class_weight': 'balanced'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Non-Linear SVC with Best Hyperparameters F1-scores:\")\n",
    "print('train:', custom_f1_score(y_train, nonlinear_svc.predict(X_train_tfidf)))\n",
    "print('val:  ', custom_f1_score(y_val  , nonlinear_svc.predict(X_val_tfidf)))\n",
    "print('test: ', custom_f1_score(y_test , nonlinear_svc.predict(X_test_tfidf)))\n",
    "\n",
    "print(nonlinear_svc.estimators_[0].get_params())\n",
    "print(\"\\nBest hyperparameters:\")\n",
    "print(svc_nonlinear_study.best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7898c2fe",
   "metadata": {},
   "source": [
    "### PhoW2V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9c67dd2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-19 16:58:16,197] A new study created in memory with name: no-name-80b2ccf6-6b58-4b74-943c-67585c4c41ff\n",
      "[I 2025-12-19 16:58:16,884] Trial 0 finished with value: 0.5715 and parameters: {'kernel': 'poly', 'C': 19.765599562374707, 'gamma': 'auto', 'class_weight': None, 'degree': 2}. Best is trial 0 with value: 0.5715.\n",
      "[I 2025-12-19 16:58:18,394] Trial 1 finished with value: 0.6398 and parameters: {'kernel': 'rbf', 'C': 11.71199658483352, 'gamma': 'scale', 'class_weight': None}. Best is trial 1 with value: 0.6398.\n",
      "[I 2025-12-19 16:58:21,153] Trial 2 finished with value: 0.5386 and parameters: {'kernel': 'rbf', 'C': 6.9177316302209935, 'gamma': 'scale', 'class_weight': 'balanced'}. Best is trial 1 with value: 0.6398.\n",
      "[I 2025-12-19 16:58:22,788] Trial 3 finished with value: 0.5741 and parameters: {'kernel': 'poly', 'C': 41.338016019468874, 'gamma': 'scale', 'class_weight': 'balanced', 'degree': 2}. Best is trial 1 with value: 0.6398.\n",
      "[I 2025-12-19 16:58:31,722] Trial 4 finished with value: 0.032 and parameters: {'kernel': 'rbf', 'C': 0.0043819711016756845, 'gamma': 'auto', 'class_weight': 'balanced'}. Best is trial 1 with value: 0.6398.\n"
     ]
    }
   ],
   "source": [
    "def nonlinear_svc_objective(trial):\n",
    "    kernel_choice = trial.suggest_categorical('kernel', ['rbf', 'poly', 'sigmoid'])\n",
    "    \n",
    "    params = dict(\n",
    "        C=trial.suggest_float('C', 1e-3, 100, log=True),\n",
    "        kernel=kernel_choice,\n",
    "        gamma=trial.suggest_categorical('gamma', ['scale', 'auto']), \n",
    "        class_weight=trial.suggest_categorical('class_weight', ['balanced', None]),\n",
    "        random_state=42,\n",
    "        max_iter=10000 \n",
    "    )\n",
    "    \n",
    "    if kernel_choice == 'poly':\n",
    "        params['degree'] = trial.suggest_int('degree', 2, 4)\n",
    "\n",
    "    clf = MOC(SVC(**params))\n",
    "    clf.fit(X_train_phow2v, y_train)\n",
    "    trial.set_user_attr(key=\"model\", value=clf)\n",
    "\n",
    "    y_pred = clf.predict(X_val_phow2v)\n",
    "    return custom_f1_score(y_val, y_pred)\n",
    "\n",
    "sampler = TPESampler(seed=22)\n",
    "svc_nonlinear_study = optuna.create_study(sampler=sampler, direction='maximize')\n",
    "svc_nonlinear_study.optimize(nonlinear_svc_objective, n_trials=5, callbacks=[callback])\n",
    "\n",
    "nonlinear_svc = svc_nonlinear_study.user_attrs['best_model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "65eeb680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-Linear SVC with Best Hyperparameters F1-scores:\n",
      "train: 0.7073\n",
      "val:   0.6398\n",
      "test:  0.6436\n",
      "{'C': 11.71199658483352, 'break_ties': False, 'cache_size': 200, 'class_weight': None, 'coef0': 0.0, 'decision_function_shape': 'ovr', 'degree': 3, 'gamma': 'scale', 'kernel': 'rbf', 'max_iter': 10000, 'probability': False, 'random_state': 42, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n",
      "\n",
      "Best hyperparameters:\n",
      "{'kernel': 'rbf', 'C': 11.71199658483352, 'gamma': 'scale', 'class_weight': None}\n"
     ]
    }
   ],
   "source": [
    "print(\"Non-Linear SVC with Best Hyperparameters F1-scores:\")\n",
    "print('train:', custom_f1_score(y_train, nonlinear_svc.predict(X_train_phow2v)))\n",
    "print('val:  ', custom_f1_score(y_val  , nonlinear_svc.predict(X_val_phow2v)))\n",
    "print('test: ', custom_f1_score(y_test , nonlinear_svc.predict(X_test_phow2v)))\n",
    "\n",
    "print(nonlinear_svc.estimators_[0].get_params())\n",
    "print(\"\\nBest hyperparameters:\")\n",
    "print(svc_nonlinear_study.best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6350482",
   "metadata": {},
   "source": [
    "## MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "69173c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f994b27",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc798369",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-19 16:11:31,828] A new study created in memory with name: no-name-71318f66-9f15-4a1d-87ba-b831f676bc14\n",
      "[I 2025-12-19 16:11:32,132] Trial 0 finished with value: 0.6179 and parameters: {'alpha': 0.006820907334120959, 'fit_prior': True}. Best is trial 0 with value: 0.6179.\n",
      "[I 2025-12-19 16:11:32,236] Trial 1 finished with value: 0.583 and parameters: {'alpha': 2.733556118022411, 'fit_prior': False}. Best is trial 0 with value: 0.6179.\n",
      "[I 2025-12-19 16:11:32,340] Trial 2 finished with value: 0.6247 and parameters: {'alpha': 0.012081791403069187, 'fit_prior': True}. Best is trial 2 with value: 0.6247.\n",
      "[I 2025-12-19 16:11:32,436] Trial 3 finished with value: 0.5888 and parameters: {'alpha': 1.7693089816650007, 'fit_prior': False}. Best is trial 2 with value: 0.6247.\n",
      "[I 2025-12-19 16:11:32,537] Trial 4 finished with value: 0.5747 and parameters: {'alpha': 1.7984764264034472, 'fit_prior': True}. Best is trial 2 with value: 0.6247.\n",
      "[I 2025-12-19 16:11:32,634] Trial 5 finished with value: 0.6116 and parameters: {'alpha': 0.0010581895426425357, 'fit_prior': False}. Best is trial 2 with value: 0.6247.\n",
      "[I 2025-12-19 16:11:32,750] Trial 6 finished with value: 0.615 and parameters: {'alpha': 0.6423201352834903, 'fit_prior': False}. Best is trial 2 with value: 0.6247.\n",
      "[I 2025-12-19 16:11:32,865] Trial 7 finished with value: 0.6205 and parameters: {'alpha': 0.5660741193202661, 'fit_prior': False}. Best is trial 2 with value: 0.6247.\n",
      "[I 2025-12-19 16:11:32,981] Trial 8 finished with value: 0.6237 and parameters: {'alpha': 0.05131223828514265, 'fit_prior': False}. Best is trial 2 with value: 0.6247.\n",
      "[I 2025-12-19 16:11:33,090] Trial 9 finished with value: 0.6178 and parameters: {'alpha': 0.0028027262915760165, 'fit_prior': False}. Best is trial 2 with value: 0.6247.\n",
      "[I 2025-12-19 16:11:33,209] Trial 10 finished with value: 0.6259 and parameters: {'alpha': 0.028334307200207614, 'fit_prior': True}. Best is trial 10 with value: 0.6259.\n",
      "[I 2025-12-19 16:11:33,323] Trial 11 finished with value: 0.6261 and parameters: {'alpha': 0.026447101800279923, 'fit_prior': True}. Best is trial 11 with value: 0.6261.\n",
      "[I 2025-12-19 16:11:33,441] Trial 12 finished with value: 0.6287 and parameters: {'alpha': 0.058601842417311256, 'fit_prior': True}. Best is trial 12 with value: 0.6287.\n",
      "[I 2025-12-19 16:11:33,563] Trial 13 finished with value: 0.6206 and parameters: {'alpha': 0.16870654436761526, 'fit_prior': True}. Best is trial 12 with value: 0.6287.\n",
      "[I 2025-12-19 16:11:33,678] Trial 14 finished with value: 0.623 and parameters: {'alpha': 0.1459310302212608, 'fit_prior': True}. Best is trial 12 with value: 0.6287.\n",
      "[I 2025-12-19 16:11:33,796] Trial 15 finished with value: 0.6269 and parameters: {'alpha': 0.024430130854351733, 'fit_prior': True}. Best is trial 12 with value: 0.6287.\n",
      "[I 2025-12-19 16:11:33,922] Trial 16 finished with value: 0.6263 and parameters: {'alpha': 0.0867246616379273, 'fit_prior': True}. Best is trial 12 with value: 0.6287.\n",
      "[I 2025-12-19 16:11:34,056] Trial 17 finished with value: 0.6216 and parameters: {'alpha': 0.009327954296916128, 'fit_prior': True}. Best is trial 12 with value: 0.6287.\n",
      "[I 2025-12-19 16:11:34,173] Trial 18 finished with value: 0.5715 and parameters: {'alpha': 9.599976813700536, 'fit_prior': True}. Best is trial 12 with value: 0.6287.\n",
      "[I 2025-12-19 16:11:34,289] Trial 19 finished with value: 0.6113 and parameters: {'alpha': 0.27124640379904424, 'fit_prior': True}. Best is trial 12 with value: 0.6287.\n",
      "[I 2025-12-19 16:11:34,407] Trial 20 finished with value: 0.6155 and parameters: {'alpha': 0.0036079120704982036, 'fit_prior': True}. Best is trial 12 with value: 0.6287.\n",
      "[I 2025-12-19 16:11:34,524] Trial 21 finished with value: 0.6277 and parameters: {'alpha': 0.06177428035504189, 'fit_prior': True}. Best is trial 12 with value: 0.6287.\n",
      "[I 2025-12-19 16:11:34,643] Trial 22 finished with value: 0.6261 and parameters: {'alpha': 0.03037524860688228, 'fit_prior': True}. Best is trial 12 with value: 0.6287.\n",
      "[I 2025-12-19 16:11:34,761] Trial 23 finished with value: 0.6279 and parameters: {'alpha': 0.06099739826847769, 'fit_prior': True}. Best is trial 12 with value: 0.6287.\n",
      "[I 2025-12-19 16:11:34,884] Trial 24 finished with value: 0.6271 and parameters: {'alpha': 0.06575674290458942, 'fit_prior': True}. Best is trial 12 with value: 0.6287.\n",
      "[I 2025-12-19 16:11:35,004] Trial 25 finished with value: 0.5972 and parameters: {'alpha': 0.36569267608142036, 'fit_prior': True}. Best is trial 12 with value: 0.6287.\n",
      "[I 2025-12-19 16:11:35,120] Trial 26 finished with value: 0.6303 and parameters: {'alpha': 0.051433368551114446, 'fit_prior': True}. Best is trial 26 with value: 0.6303.\n",
      "[I 2025-12-19 16:11:35,225] Trial 27 finished with value: 0.6249 and parameters: {'alpha': 0.015567657009693548, 'fit_prior': True}. Best is trial 26 with value: 0.6303.\n",
      "[I 2025-12-19 16:11:35,334] Trial 28 finished with value: 0.6233 and parameters: {'alpha': 0.1437430289478449, 'fit_prior': True}. Best is trial 26 with value: 0.6303.\n",
      "[I 2025-12-19 16:11:35,440] Trial 29 finished with value: 0.6146 and parameters: {'alpha': 0.00476120329153068, 'fit_prior': True}. Best is trial 26 with value: 0.6303.\n",
      "[I 2025-12-19 16:11:35,548] Trial 30 finished with value: 0.6058 and parameters: {'alpha': 0.30959290873143896, 'fit_prior': True}. Best is trial 26 with value: 0.6303.\n",
      "[I 2025-12-19 16:11:35,657] Trial 31 finished with value: 0.6288 and parameters: {'alpha': 0.047396003470671084, 'fit_prior': True}. Best is trial 26 with value: 0.6303.\n",
      "[I 2025-12-19 16:11:35,768] Trial 32 finished with value: 0.6285 and parameters: {'alpha': 0.04180243688072341, 'fit_prior': True}. Best is trial 26 with value: 0.6303.\n",
      "[I 2025-12-19 16:11:35,881] Trial 33 finished with value: 0.6243 and parameters: {'alpha': 0.014233394294773091, 'fit_prior': True}. Best is trial 26 with value: 0.6303.\n",
      "[I 2025-12-19 16:11:35,993] Trial 34 finished with value: 0.6271 and parameters: {'alpha': 0.03584142751536381, 'fit_prior': True}. Best is trial 26 with value: 0.6303.\n",
      "[I 2025-12-19 16:11:36,102] Trial 35 finished with value: 0.6234 and parameters: {'alpha': 0.11663694122535091, 'fit_prior': True}. Best is trial 26 with value: 0.6303.\n",
      "[I 2025-12-19 16:11:36,227] Trial 36 finished with value: 0.6241 and parameters: {'alpha': 0.016369252747701176, 'fit_prior': True}. Best is trial 26 with value: 0.6303.\n",
      "[I 2025-12-19 16:11:36,344] Trial 37 finished with value: 0.6178 and parameters: {'alpha': 0.007731139672452851, 'fit_prior': False}. Best is trial 26 with value: 0.6303.\n",
      "[I 2025-12-19 16:11:36,459] Trial 38 finished with value: 0.625 and parameters: {'alpha': 0.09449355676017332, 'fit_prior': True}. Best is trial 26 with value: 0.6303.\n",
      "[I 2025-12-19 16:11:36,577] Trial 39 finished with value: 0.6064 and parameters: {'alpha': 0.8913317692388054, 'fit_prior': False}. Best is trial 26 with value: 0.6303.\n",
      "[I 2025-12-19 16:11:36,689] Trial 40 finished with value: 0.6209 and parameters: {'alpha': 0.20852603913587187, 'fit_prior': True}. Best is trial 26 with value: 0.6303.\n",
      "[I 2025-12-19 16:11:36,805] Trial 41 finished with value: 0.6293 and parameters: {'alpha': 0.04686627705243849, 'fit_prior': True}. Best is trial 26 with value: 0.6303.\n",
      "[I 2025-12-19 16:11:36,921] Trial 42 finished with value: 0.6285 and parameters: {'alpha': 0.04363465828081135, 'fit_prior': True}. Best is trial 26 with value: 0.6303.\n",
      "[I 2025-12-19 16:11:37,039] Trial 43 finished with value: 0.6254 and parameters: {'alpha': 0.019373034964868772, 'fit_prior': True}. Best is trial 26 with value: 0.6303.\n",
      "[I 2025-12-19 16:11:37,158] Trial 44 finished with value: 0.6222 and parameters: {'alpha': 0.04746538535005125, 'fit_prior': False}. Best is trial 26 with value: 0.6303.\n",
      "[I 2025-12-19 16:11:37,283] Trial 45 finished with value: 0.6265 and parameters: {'alpha': 0.08763319956233914, 'fit_prior': True}. Best is trial 26 with value: 0.6303.\n",
      "[I 2025-12-19 16:11:37,428] Trial 46 finished with value: 0.6066 and parameters: {'alpha': 0.0012166588290468954, 'fit_prior': True}. Best is trial 26 with value: 0.6303.\n",
      "[I 2025-12-19 16:11:37,552] Trial 47 finished with value: 0.6225 and parameters: {'alpha': 0.00969800729109487, 'fit_prior': True}. Best is trial 26 with value: 0.6303.\n",
      "[I 2025-12-19 16:11:37,678] Trial 48 finished with value: 0.6254 and parameters: {'alpha': 0.04133630522299501, 'fit_prior': False}. Best is trial 26 with value: 0.6303.\n",
      "[I 2025-12-19 16:11:37,808] Trial 49 finished with value: 0.6254 and parameters: {'alpha': 0.02139712258988971, 'fit_prior': True}. Best is trial 26 with value: 0.6303.\n"
     ]
    }
   ],
   "source": [
    "def multinomial_nb_objective(trial):\n",
    "    params = dict(\n",
    "        alpha=trial.suggest_float('alpha', 1e-3, 10, log=True),\n",
    "        fit_prior=trial.suggest_categorical('fit_prior', [True, False])\n",
    "    )\n",
    "    \n",
    "    clf = MOC(MultinomialNB(**params))\n",
    "    clf.fit(X_train_tfidf, y_train)\n",
    "    trial.set_user_attr(key=\"model\", value=clf)\n",
    "\n",
    "    y_pred = clf.predict(X_val_tfidf)\n",
    "    return custom_f1_score(y_val, y_pred)\n",
    "\n",
    "sampler = TPESampler(seed=22)\n",
    "nb_study = optuna.create_study(sampler=sampler, direction='maximize')\n",
    "nb_study.optimize(multinomial_nb_objective, n_trials=50, callbacks=[callback])\n",
    "\n",
    "nb_model = nb_study.user_attrs['best_model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06a7988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB with Best Hyperparameters F1-scores:\n",
      "train: 0.9779\n",
      "dev:   0.6303\n",
      "test:  0.6308\n",
      "{'alpha': 0.051433368551114446, 'class_prior': None, 'fit_prior': True, 'force_alpha': True}\n",
      "\n",
      "Best hyperparameters:\n",
      "{'alpha': 0.051433368551114446, 'fit_prior': True}\n"
     ]
    }
   ],
   "source": [
    "print(\"MultinomialNB with Best Hyperparameters F1-scores:\")\n",
    "print('train:', custom_f1_score(y_train, nb_model.predict(X_train_tfidf)))\n",
    "print('val:  ', custom_f1_score(y_val  , nb_model.predict(X_val_tfidf)))\n",
    "print('test: ', custom_f1_score(y_test , nb_model.predict(X_test_tfidf)))\n",
    "\n",
    "print(nb_model.estimators_[0].get_params())\n",
    "print(\"\\nBest hyperparameters:\")\n",
    "print(nb_study.best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39fbafb0",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b758f3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4599109c",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998deaca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-19 16:11:46,727] A new study created in memory with name: no-name-55d69582-7cbe-4480-b0be-dfb5a1c650dd\n",
      "[I 2025-12-19 16:11:54,833] Trial 0 finished with value: 0.6408 and parameters: {'n_estimators': 81, 'max_depth': 53, 'min_samples_split': 7, 'min_samples_leaf': 9, 'class_weight': 'balanced_subsample'}. Best is trial 0 with value: 0.6408.\n",
      "[I 2025-12-19 16:12:10,664] Trial 1 finished with value: 0.648 and parameters: {'n_estimators': 154, 'max_depth': 30, 'min_samples_split': 13, 'min_samples_leaf': 1, 'class_weight': 'balanced_subsample'}. Best is trial 1 with value: 0.648.\n",
      "[I 2025-12-19 16:12:16,872] Trial 2 finished with value: 0.5911 and parameters: {'n_estimators': 78, 'max_depth': 10, 'min_samples_split': 12, 'min_samples_leaf': 10, 'class_weight': None}. Best is trial 1 with value: 0.648.\n",
      "[I 2025-12-19 16:12:32,252] Trial 3 finished with value: 0.6723 and parameters: {'n_estimators': 153, 'max_depth': 45, 'min_samples_split': 10, 'min_samples_leaf': 5, 'class_weight': 'balanced_subsample'}. Best is trial 3 with value: 0.6723.\n",
      "[I 2025-12-19 16:12:45,611] Trial 4 finished with value: 0.6057 and parameters: {'n_estimators': 189, 'max_depth': 99, 'min_samples_split': 11, 'min_samples_leaf': 8, 'class_weight': None}. Best is trial 3 with value: 0.6723.\n",
      "[I 2025-12-19 16:12:57,622] Trial 5 finished with value: 0.6696 and parameters: {'n_estimators': 162, 'max_depth': 56, 'min_samples_split': 3, 'min_samples_leaf': 5, 'class_weight': 'balanced'}. Best is trial 3 with value: 0.6723.\n",
      "[I 2025-12-19 16:13:06,144] Trial 6 finished with value: 0.6503 and parameters: {'n_estimators': 116, 'max_depth': 18, 'min_samples_split': 2, 'min_samples_leaf': 7, 'class_weight': 'balanced'}. Best is trial 3 with value: 0.6723.\n",
      "[I 2025-12-19 16:13:17,868] Trial 7 finished with value: 0.6499 and parameters: {'n_estimators': 121, 'max_depth': 27, 'min_samples_split': 12, 'min_samples_leaf': 7, 'class_weight': 'balanced_subsample'}. Best is trial 3 with value: 0.6723.\n",
      "[I 2025-12-19 16:13:24,782] Trial 8 finished with value: 0.6584 and parameters: {'n_estimators': 83, 'max_depth': 25, 'min_samples_split': 9, 'min_samples_leaf': 4, 'class_weight': 'balanced'}. Best is trial 3 with value: 0.6723.\n",
      "[I 2025-12-19 16:13:33,232] Trial 9 finished with value: 0.6389 and parameters: {'n_estimators': 83, 'max_depth': 77, 'min_samples_split': 13, 'min_samples_leaf': 8, 'class_weight': 'balanced_subsample'}. Best is trial 3 with value: 0.6723.\n"
     ]
    }
   ],
   "source": [
    "def rf_objective(trial):\n",
    "    params = dict(\n",
    "        n_estimators=trial.suggest_int('n_estimators', 50, 200),\n",
    "        max_depth=trial.suggest_int('max_depth', 10, 100),\n",
    "        min_samples_split=trial.suggest_int('min_samples_split', 2, 15),\n",
    "        min_samples_leaf=trial.suggest_int('min_samples_leaf', 1, 10),\n",
    "        class_weight=trial.suggest_categorical('class_weight', ['balanced', 'balanced_subsample', None]),\n",
    "        n_jobs=-1, \n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    clf = MOC(RandomForestClassifier(**params))\n",
    "    clf.fit(X_train_tfidf, y_train)\n",
    "    trial.set_user_attr(key=\"model\", value=clf)\n",
    "\n",
    "    y_pred = clf.predict(X_val_tfidf)\n",
    "    return custom_f1_score(y_val, y_pred)\n",
    "\n",
    "sampler = TPESampler(seed=22)\n",
    "rf_study = optuna.create_study(sampler=sampler, direction='maximize')\n",
    "rf_study.optimize(rf_objective, n_trials=10, callbacks=[callback])\n",
    "\n",
    "rf_model = rf_study.user_attrs['best_model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6458ff02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier with Best Hyperparameters F1-scores:\n",
      "train: 0.9297\n",
      "dev:   0.6723\n",
      "test:  0.6878\n",
      "{'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': 'balanced_subsample', 'criterion': 'gini', 'max_depth': 45, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 5, 'min_samples_split': 10, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 153, 'n_jobs': -1, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "Best hyperparameters:\n",
      "{'n_estimators': 153, 'max_depth': 45, 'min_samples_split': 10, 'min_samples_leaf': 5, 'class_weight': 'balanced_subsample'}\n"
     ]
    }
   ],
   "source": [
    "print(\"RandomForestClassifier with Best Hyperparameters F1-scores:\")\n",
    "print('train:', custom_f1_score(y_train, rf_model.predict(X_train_tfidf)))\n",
    "print('val:  ', custom_f1_score(y_val  , rf_model.predict(X_val_tfidf)))\n",
    "print('test: ', custom_f1_score(y_test , rf_model.predict(X_test_tfidf)))\n",
    "\n",
    "print(rf_model.estimators_[0].get_params())\n",
    "print(\"\\nBest hyperparameters:\")\n",
    "print(rf_study.best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2101ef7",
   "metadata": {},
   "source": [
    "# **PhoBERT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1794f7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoModel, AutoConfig\n",
    "import torch.nn as nn\n",
    "from torch.optim import AdamW\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7955b2d",
   "metadata": {},
   "source": [
    "## VLSP2018 DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92915230",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "from datasets import load_dataset\n",
    "\n",
    "\n",
    "class PolarityMapping:\n",
    "    INDEX_TO_POLARITY = { 0: None, 1: 'positive', 2: 'negative', 3: 'neutral' }\n",
    "    INDEX_TO_ONEHOT = { 0: [1, 0, 0, 0], 1: [0, 1, 0, 0], 2: [0, 0, 1, 0], 3: [0, 0, 0, 1] }\n",
    "    POLARITY_TO_INDEX = { None: 0, 'positive': 1, 'negative': 2, 'neutral': 3 }\n",
    "\n",
    "\n",
    "class VLSP2018Loader:\n",
    "\n",
    "    @staticmethod\n",
    "    def load(train_csv_path, val_csv_path, test_csv_path):\n",
    "        dataset_paths = {'train': train_csv_path, 'val': val_csv_path, 'test': test_csv_path}\n",
    "        raw_datasets = load_dataset('csv', data_files={ k: v for k, v in dataset_paths.items() if v })\n",
    "        return raw_datasets\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def preprocess_and_tokenize(text_data, preprocessor, tokenizer, batch_size, max_length):\n",
    "        print('[INFO] Preprocessing and tokenizing text data...')\n",
    "        def transform_each_batch(batch):\n",
    "            preprocessed_batch = preprocessor.process_batch(batch)\n",
    "            return tokenizer(preprocessed_batch, max_length=max_length, padding='max_length', truncation=True)\n",
    "\n",
    "        if type(text_data) == str: return transform_each_batch([text_data])\n",
    "        return text_data.map(\n",
    "            lambda reviews: transform_each_batch(reviews['Review']),\n",
    "            batched=True, batch_size=batch_size\n",
    "        ).remove_columns('Review')\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def labels_to_flatten_onehot(datasets):\n",
    "        print('[INFO] Transforming \"Aspect#Categoy,Polarity\" labels to flattened one-hot encoding...')\n",
    "        model_input_names = ['input_ids', 'token_type_ids', 'attention_mask']\n",
    "        label_columns = [col for col in datasets['train'].column_names if col not in ['Review', *model_input_names]]\n",
    "        def transform_each_review(review): # Convert each Aspect#Categoy,Polarity to one-hot encoding and merge them into 1D list\n",
    "            review['FlattenOneHotLabels'] = sum([\n",
    "                PolarityMapping.INDEX_TO_ONEHOT[review[aspect_category]] # Get one-hot encoding\n",
    "                for aspect_category in label_columns\n",
    "            ], []) # Need to be flattened to match the model's output shape\n",
    "            return review\n",
    "        return datasets.map(transform_each_review, num_proc=8).select_columns(['FlattenOneHotLabels', *model_input_names])\n",
    "\n",
    "\n",
    "class VLSP2018Parser:\n",
    "    def __init__(self, train_txt_path, val_txt_path=None, test_txt_path=None):\n",
    "        self.dataset_paths = { 'train': train_txt_path, 'val': val_txt_path, 'test': test_txt_path }\n",
    "        self.reviews = { 'train': [], 'val': [], 'test': [] }\n",
    "        self.aspect_categories = set()\n",
    "\n",
    "        for dataset_type, txt_path in self.dataset_paths.items():\n",
    "            if not txt_path:\n",
    "                self.dataset_paths.pop(dataset_type)\n",
    "                self.reviews.pop(dataset_type)\n",
    "        self._parse_input_files()\n",
    "\n",
    "\n",
    "    def _parse_input_files(self):\n",
    "        print(f'[INFO] Parsing {len(self.dataset_paths)} input files...')\n",
    "        for dataset_type, txt_path in self.dataset_paths.items():\n",
    "            with open(txt_path, 'r', encoding='utf-8') as txt_file:\n",
    "                content = txt_file.read()\n",
    "                review_blocks = content.strip().split('\\n\\n')\n",
    "\n",
    "                for block in tqdm(review_blocks):\n",
    "                    lines = block.split('\\n')\n",
    "                    sentiment_info = re.findall(r'\\{([^,]+)#([^,]+), ([^}]+)\\}', lines[2].strip())\n",
    "\n",
    "                    review_data = {}\n",
    "                    for aspect, category, polarity in sentiment_info:\n",
    "                        aspect_category = f'{aspect.strip()}#{category.strip()}'\n",
    "                        self.aspect_categories.add(aspect_category)\n",
    "                        review_data[aspect_category] = PolarityMapping.POLARITY_TO_INDEX[polarity.strip()]\n",
    "\n",
    "                    self.reviews[dataset_type].append((lines[1].strip(), review_data))\n",
    "        self.aspect_categories = sorted(self.aspect_categories)\n",
    "\n",
    "\n",
    "    def txt2csv(self):\n",
    "        print('[INFO] Converting parsed data to CSV files...')\n",
    "        for dataset, txt_path in self.dataset_paths.items():\n",
    "            csv_path = txt_path.replace('.txt', '.csv')\n",
    "\n",
    "            with open(csv_path, 'w', newline='', encoding='utf-8') as csv_file:\n",
    "                writer = csv.writer(csv_file)\n",
    "                writer.writerow(['Review'] + self.aspect_categories)\n",
    "\n",
    "                for review_text, review_data in tqdm(self.reviews[dataset]):\n",
    "                    row = [review_text] + [review_data.get(aspect_category, 0) for aspect_category in self.aspect_categories]\n",
    "                    writer.writerow(row)\n",
    "\n",
    "    @staticmethod\n",
    "    def vlsp_save_as(save_path, raw_texts, encoded_review_labels, aspect_category_names):\n",
    "        with open(save_path, 'w', encoding='utf-8') as file:\n",
    "            for index, encoded_label in tqdm(enumerate(encoded_review_labels)):\n",
    "                polarities = map(lambda x: PolarityMapping.INDEX_TO_POLARITY[x], encoded_label)\n",
    "                acsa = ', '.join(\n",
    "                    f'{{{aspect_category}, {polarity}}}'\n",
    "                    for aspect_category, polarity in zip(aspect_category_names, polarities) if polarity\n",
    "                )\n",
    "                file.write(f\"#{index + 1}\\n{raw_texts[index]}\\n{acsa}\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff3b21b",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98073050",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = r'Data/Preprocessed/1-train-clean.csv'\n",
    "VAL_PATH = r'Data/Preprocessed/2-val-clean.csv'\n",
    "TEST_PATH = r'Data/Preprocessed/3-test-clean.csv'\n",
    "PRETRAINED_MODEL = 'vinai/phobert-base'\n",
    "MAX_LENGTH = 256\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 30\n",
    "NUM_CLASSES = 4 # Giả định: 0: None, 1: Pos, 2: Neg, 3: Neu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81b25cc",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2d797f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d108cbfe4c34f4e9c08b83a345c0a24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d114f9371ff14fe98874c4f36d2a9f06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating val split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "639f436924654bfd849858d2e38835f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['review_clean', 'hotel#general', 'hotel#prices', 'hotel#design&features', 'hotel#cleanliness', 'hotel#comfort', 'hotel#quality', 'hotel#miscellaneous', 'rooms#general', 'rooms#prices', 'rooms#design&features', 'rooms#cleanliness', 'rooms#comfort', 'rooms#quality', 'rooms#miscellaneous', 'room_amenities#general', 'room_amenities#prices', 'room_amenities#design&features', 'room_amenities#cleanliness', 'room_amenities#comfort', 'room_amenities#quality', 'room_amenities#miscellaneous', 'facilities#general', 'facilities#prices', 'facilities#design&features', 'facilities#cleanliness', 'facilities#comfort', 'facilities#quality', 'facilities#miscellaneous', 'service#general', 'location#general', 'food&drinks#prices', 'food&drinks#quality', 'food&drinks#style&options', 'food&drinks#miscellaneous'],\n",
       "        num_rows: 1658\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['review_clean', 'hotel#general', 'hotel#prices', 'hotel#design&features', 'hotel#cleanliness', 'hotel#comfort', 'hotel#quality', 'hotel#miscellaneous', 'rooms#general', 'rooms#prices', 'rooms#design&features', 'rooms#cleanliness', 'rooms#comfort', 'rooms#quality', 'rooms#miscellaneous', 'room_amenities#general', 'room_amenities#prices', 'room_amenities#design&features', 'room_amenities#cleanliness', 'room_amenities#comfort', 'room_amenities#quality', 'room_amenities#miscellaneous', 'facilities#general', 'facilities#prices', 'facilities#design&features', 'facilities#cleanliness', 'facilities#comfort', 'facilities#quality', 'facilities#miscellaneous', 'service#general', 'location#general', 'food&drinks#prices', 'food&drinks#quality', 'food&drinks#style&options', 'food&drinks#miscellaneous'],\n",
       "        num_rows: 359\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['review_clean', 'hotel#general', 'hotel#prices', 'hotel#design&features', 'hotel#cleanliness', 'hotel#comfort', 'hotel#quality', 'hotel#miscellaneous', 'rooms#general', 'rooms#prices', 'rooms#design&features', 'rooms#cleanliness', 'rooms#comfort', 'rooms#quality', 'rooms#miscellaneous', 'room_amenities#general', 'room_amenities#prices', 'room_amenities#design&features', 'room_amenities#cleanliness', 'room_amenities#comfort', 'room_amenities#quality', 'room_amenities#miscellaneous', 'facilities#general', 'facilities#prices', 'facilities#design&features', 'facilities#cleanliness', 'facilities#comfort', 'facilities#quality', 'facilities#miscellaneous', 'service#general', 'location#general', 'food&drinks#prices', 'food&drinks#quality', 'food&drinks#style&options', 'food&drinks#miscellaneous'],\n",
       "        num_rows: 372\n",
       "    })\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "raw_datasets = VLSP2018Loader.load(TRAIN_PATH, VAL_PATH, TEST_PATH)\n",
    "raw_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548779b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số lượng Aspects cần dự đoán: 34\n"
     ]
    }
   ],
   "source": [
    "ignore_cols = ['review_clean']\n",
    "label_cols = [col for col in raw_datasets['train'].column_names if col not in ignore_cols]\n",
    "print(f\"Số lượng Aspects cần dự đoán: {len(label_cols)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b5b39a",
   "metadata": {},
   "source": [
    "## Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc890474",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "178a8c2776b64f81ba317b7e84dd245e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/557 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "752b5949c64c432ab91d1dd0a682ad65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d760b0aca0e24d47b71b59976967a0cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "bpe.codes: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "051736a0fd064df2af7e17464aad422d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8220624beb71485ab76d68ee30db56cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1658 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04895e57fc85463185fc6999038ed47d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/359 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68f06c23a0ec4082a6577979746444fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/372 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(PRETRAINED_MODEL)\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(\n",
    "        examples['review_clean'],\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        max_length=MAX_LENGTH\n",
    "    )\n",
    "\n",
    "tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33eb39b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. FORMAT CHO PYTORCH ---\n",
    "# Xóa cột text gốc để nhẹ bộ nhớ\n",
    "tokenized_datasets = tokenized_datasets.remove_columns(['review_clean'])\n",
    "\n",
    "# Định nghĩa các cột cần giữ lại (Gồm input của model + các cột label gốc)\n",
    "input_cols = ['input_ids', 'attention_mask', 'token_type_ids']\n",
    "cols_to_keep = input_cols + label_cols\n",
    "\n",
    "# Quan trọng: Chuyển toàn bộ sang Tensor\n",
    "tokenized_datasets.set_format(\"torch\", columns=cols_to_keep)\n",
    "\n",
    "# Tạo DataLoader\n",
    "train_dataloader = DataLoader(tokenized_datasets['train'], shuffle=True, batch_size=BATCH_SIZE)\n",
    "val_dataloader = DataLoader(tokenized_datasets['val'], batch_size=BATCH_SIZE)\n",
    "test_dataloader = DataLoader(tokenized_datasets['test'], batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c372594",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d8ce5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PhoBertABSA(nn.Module):\n",
    "    def __init__(self, model_name, aspect_names, num_classes):\n",
    "        super().__init__()\n",
    "        self.phobert = AutoModel.from_pretrained(model_name)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "        # Dùng ModuleDict để lưu các layer theo tên cột (không cần đổi tên)\n",
    "        # Ví dụ: self.classifiers['hotel#prices'] là một lớp Linear riêng\n",
    "        self.classifiers = nn.ModuleDict({\n",
    "            name: nn.Linear(768, num_classes) for name in aspect_names\n",
    "        })\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "        # 1. Chạy PhoBERT\n",
    "        outputs = self.phobert(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids\n",
    "        )\n",
    "        # Lấy vector đặc trưng của câu (CLS token)\n",
    "        pooled_output = outputs.pooler_output\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "\n",
    "        # 2. Chạy qua từng nhánh aspect\n",
    "        logits_dict = {}\n",
    "        for name, classifier in self.classifiers.items():\n",
    "            logits_dict[name] = classifier(pooled_output)\n",
    "\n",
    "        return logits_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4121a2ed",
   "metadata": {},
   "source": [
    "### Train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4c16bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(model, dataloader, optimizer, device, loss_fn):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    progress_bar = tqdm(dataloader, desc=\"Training\")\n",
    "\n",
    "    for batch in progress_bar:\n",
    "        # Đẩy input vào GPU\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        token_type_ids = batch['token_type_ids'].to(device)\n",
    "\n",
    "        # Reset gradient\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass (Model dự đoán)\n",
    "        logits_dict = model(input_ids, attention_mask, token_type_ids)\n",
    "\n",
    "        # Tính Loss tổng\n",
    "        batch_loss = 0\n",
    "        for aspect_name in label_cols:\n",
    "            # Lấy nhãn thật của aspect này từ batch\n",
    "            labels = batch[aspect_name].to(device)\n",
    "\n",
    "            # Lấy dự đoán của aspect này\n",
    "            logits = logits_dict[aspect_name]\n",
    "\n",
    "            # Cộng dồn loss (CrossEntropy)\n",
    "            batch_loss += loss_fn(logits, labels)\n",
    "\n",
    "        # Backward pass\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += batch_loss.item()\n",
    "        progress_bar.set_postfix({'loss': batch_loss.item()})\n",
    "\n",
    "    return total_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b8bf3a",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd19b90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eed3c600a57442ba9fe5eb211845e91a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/543M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rTraining:   0%|          | 0/104 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b9acf6bde3440959b132fddd01e427b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/543M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [01:05<00:00,  1.58it/s, loss=11.7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Train Loss: 24.2506\n",
      "\n",
      "Epoch 2/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [01:11<00:00,  1.46it/s, loss=10.3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Train Loss: 10.2001\n",
      "\n",
      "Epoch 3/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [01:09<00:00,  1.49it/s, loss=8.59]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Train Loss: 8.8840\n",
      "\n",
      "Epoch 4/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [01:10<00:00,  1.48it/s, loss=8.14]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Train Loss: 8.4951\n",
      "\n",
      "Epoch 5/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [01:09<00:00,  1.49it/s, loss=7.08]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Train Loss: 7.9871\n",
      "\n",
      "Epoch 6/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [01:09<00:00,  1.49it/s, loss=6.93]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Train Loss: 7.5021\n",
      "\n",
      "Epoch 7/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [01:09<00:00,  1.50it/s, loss=6.64]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Train Loss: 7.0720\n",
      "\n",
      "Epoch 8/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [01:09<00:00,  1.49it/s, loss=7.14]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Train Loss: 6.7008\n",
      "\n",
      "Epoch 9/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [01:10<00:00,  1.49it/s, loss=8.19]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Train Loss: 6.3030\n",
      "\n",
      "Epoch 10/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [01:09<00:00,  1.49it/s, loss=6.07]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Train Loss: 5.9087\n",
      "\n",
      "Epoch 11/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [01:09<00:00,  1.50it/s, loss=4.8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Train Loss: 5.5401\n",
      "\n",
      "Epoch 12/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [01:09<00:00,  1.50it/s, loss=4.53]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Train Loss: 5.1728\n",
      "\n",
      "Epoch 13/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [01:09<00:00,  1.50it/s, loss=5.15]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Train Loss: 4.8548\n",
      "\n",
      "Epoch 14/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [01:09<00:00,  1.49it/s, loss=5.08]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Train Loss: 4.4984\n",
      "\n",
      "Epoch 15/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [01:09<00:00,  1.50it/s, loss=6.43]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Train Loss: 4.1665\n",
      "\n",
      "Epoch 16/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [01:09<00:00,  1.50it/s, loss=5.07]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Train Loss: 3.8498\n",
      "\n",
      "Epoch 17/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [01:09<00:00,  1.50it/s, loss=4.21]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Train Loss: 3.5601\n",
      "\n",
      "Epoch 18/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [01:09<00:00,  1.50it/s, loss=4.99]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Train Loss: 3.3313\n",
      "\n",
      "Epoch 19/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [01:09<00:00,  1.50it/s, loss=3.68]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Train Loss: 3.0640\n",
      "\n",
      "Epoch 20/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [01:09<00:00,  1.50it/s, loss=2.95]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Train Loss: 2.8878\n",
      "\n",
      "Epoch 21/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [01:09<00:00,  1.50it/s, loss=1.95]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Train Loss: 2.6794\n",
      "\n",
      "Epoch 22/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [01:09<00:00,  1.50it/s, loss=1.57]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Train Loss: 2.5078\n",
      "\n",
      "Epoch 23/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [01:09<00:00,  1.50it/s, loss=1.69]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Train Loss: 2.3504\n",
      "\n",
      "Epoch 24/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [01:09<00:00,  1.50it/s, loss=2.89]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Train Loss: 2.2287\n",
      "\n",
      "Epoch 25/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [01:09<00:00,  1.49it/s, loss=2.34]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Train Loss: 2.0983\n",
      "\n",
      "Epoch 26/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [01:09<00:00,  1.50it/s, loss=3.14]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Train Loss: 1.9717\n",
      "\n",
      "Epoch 27/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [01:09<00:00,  1.50it/s, loss=1.63]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Train Loss: 1.8599\n",
      "\n",
      "Epoch 28/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [01:09<00:00,  1.50it/s, loss=2.37]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Train Loss: 1.7503\n",
      "\n",
      "Epoch 29/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [01:09<00:00,  1.49it/s, loss=2.04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Train Loss: 1.6553\n",
      "\n",
      "Epoch 30/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [01:09<00:00,  1.50it/s, loss=3.33]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Train Loss: 1.5664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. Setup thiết bị\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# 2. Khởi tạo Model\n",
    "model = PhoBertABSA(PRETRAINED_MODEL, label_cols, NUM_CLASSES)\n",
    "model.to(device)\n",
    "\n",
    "# 3. Setup Optimizer\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# 4. Bắt đầu Train\n",
    "print(\"Start Training...\")\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"\\nEpoch {epoch + 1}/{EPOCHS}\")\n",
    "\n",
    "    train_loss = train_loop(model, train_dataloader, optimizer, device, loss_fn)\n",
    "    print(f\"Average Train Loss: {train_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6985ed",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7e7d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(model, dataloader, device, aspect_names):\n",
    "    model.eval() # Chuyển sang chế độ đánh giá (tắt dropout)\n",
    "\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    # Không tính gradient để tiết kiệm bộ nhớ\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Evaluating\"):\n",
    "            # 1. Đẩy input vào GPU\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            token_type_ids = batch['token_type_ids'].to(device)\n",
    "\n",
    "            # 2. Model dự đoán\n",
    "            logits_dict = model(input_ids, attention_mask, token_type_ids)\n",
    "\n",
    "            # 3. Xử lý kết quả từng Batch\n",
    "            batch_preds = []\n",
    "            batch_labels = []\n",
    "\n",
    "            # Duyệt qua từng aspect theo đúng thứ tự trong label_cols\n",
    "            for aspect in aspect_names:\n",
    "                # --- Xử lý Prediction ---\n",
    "                # Lấy logits của aspect đó\n",
    "                logits = logits_dict[aspect]\n",
    "                # Chọn class có xác suất cao nhất (argmax)\n",
    "                preds = logits.argmax(dim=-1)\n",
    "                batch_preds.append(preds.cpu().numpy())\n",
    "\n",
    "                # --- Xử lý Label thật ---\n",
    "                labels = batch[aspect]\n",
    "                batch_labels.append(labels.cpu().numpy())\n",
    "\n",
    "            # batch_preds đang là list các array [Batch_Size], ta cần stack lại\n",
    "            # Kết quả: mảng (Batch_Size, Num_Aspects)\n",
    "            all_preds.append(np.stack(batch_preds, axis=1))\n",
    "            all_labels.append(np.stack(batch_labels, axis=1))\n",
    "\n",
    "    # Nối tất cả các batch lại thành một ma trận lớn\n",
    "    # Shape cuối cùng: (Total_Samples, Num_Aspects)\n",
    "    final_preds = np.concatenate(all_preds, axis=0)\n",
    "    final_labels = np.concatenate(all_labels, axis=0)\n",
    "\n",
    "    return final_labels, final_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca12757a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đang chạy dự đoán trên tập Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 23/23 [00:04<00:00,  5.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kích thước ma trận Val: (359, 34)\n",
      "------------------------------\n",
      "Kết quả đánh giá trên tập VALIDATION:\n",
      "Micro F1-score: 0.7229\n",
      "------------------------------\n",
      "\n",
      "Đang chạy dự đoán trên tập Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 24/24 [00:04<00:00,  5.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kích thước ma trận Test: (372, 34)\n",
      "------------------------------\n",
      "Kết quả đánh giá trên tập TEST:\n",
      "Micro F1-score: 0.7383\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Đánh giá trên tập Validation (Val) ---\n",
    "print(\"Đang chạy dự đoán trên tập Validation...\")\n",
    "y_true_val, y_pred_val = get_predictions(model, val_dataloader, device, label_cols)\n",
    "\n",
    "val_micro_f1 = custom_f1_score(y_true_val, y_pred_val)\n",
    "\n",
    "print(f\"Kích thước ma trận Val: {y_pred_val.shape}\")\n",
    "print(\"-\" * 30)\n",
    "print(f\"Kết quả đánh giá trên tập VALIDATION:\")\n",
    "print(f\"Micro F1-score: {val_micro_f1}\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# --- 2. Đánh giá trên tập Test ---\n",
    "print(\"\\nĐang chạy dự đoán trên tập Test...\")\n",
    "y_true_test, y_pred_test = get_predictions(model, test_dataloader, device, label_cols)\n",
    "\n",
    "test_micro_f1 = custom_f1_score(y_true_test, y_pred_test)\n",
    "\n",
    "print(f\"Kích thước ma trận Test: {y_pred_test.shape}\")\n",
    "print(\"-\" * 30)\n",
    "print(f\"Kết quả đánh giá trên tập TEST:\")\n",
    "print(f\"Micro F1-score: {test_micro_f1}\")\n",
    "print(\"-\" * 30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
