{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "600400fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53643a25",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27ac2476",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"./VLSP2018_Hotel/Preprocessed/1-VLSP2018-SA-Hotel-train-clean.csv\")\n",
    "dev = pd.read_csv(\"./VLSP2018_Hotel/Preprocessed/2-VLSP2018-SA-Hotel-dev-clean.csv\")\n",
    "test = pd.read_csv(\"./VLSP2018_Hotel/Preprocessed/3-VLSP2018-SA-Hotel-test-clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "495d3a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train['review_clean'].tolist()\n",
    "y_train = train.drop(columns=['review_clean'])\n",
    "\n",
    "X_dev = dev['review_clean'].tolist()\n",
    "y_dev = dev.drop(columns=['review_clean'])\n",
    "\n",
    "X_test = test['review_clean'].tolist()\n",
    "y_test = test.drop(columns=['review_clean'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb96fce",
   "metadata": {},
   "source": [
    "# PhoW2V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507d6cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afaf73a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số từ vựng: 1587507\n",
      "Kích thước vector: 100\n"
     ]
    }
   ],
   "source": [
    "w2v = KeyedVectors.load_word2vec_format(\"./PhoW2V/word2vec_vi_words_100dims.bin\", binary=True)\n",
    "print(\"Số từ vựng:\", len(w2v))\n",
    "print(\"Kích thước vector:\", w2v.vector_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7c3b51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_phow2v_vectors(texts, w2v_model):\n",
    "    dim = w2v_model.vector_size\n",
    "    out = []\n",
    "    for text in texts:\n",
    "        toks = text.split() \n",
    "        vecs = [w2v_model[w] for w in toks if w in w2v_model]\n",
    "        out.append(np.mean(vecs, axis=0) if vecs else np.zeros(dim, dtype=np.float32))\n",
    "    return np.vstack(out).astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3e3e7c",
   "metadata": {},
   "source": [
    "# PhoBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e140f963",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\DS102\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3693989e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base\")\n",
    "model = AutoModel.from_pretrained(\"vinai/phobert-base\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a551500",
   "metadata": {},
   "source": [
    "**PhoBERT mean 4 last hidden**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "82ff27ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_phobert_vectors(texts, tokenizer, model, batch_size=16, max_length=128):\n",
    "    device = torch.device(\"cpu\")\n",
    "    model.to(device).eval()\n",
    "\n",
    "    # Bật lấy toàn bộ hidden states\n",
    "    model.config.output_hidden_states = True\n",
    "\n",
    "    vecs = []\n",
    "    with torch.inference_mode():\n",
    "        for i in range(0, len(texts), batch_size):\n",
    "            batch = texts[i:i+batch_size]\n",
    "            toks = tokenizer(\n",
    "                batch,\n",
    "                return_tensors=\"pt\",\n",
    "                padding=True,\n",
    "                truncation=True,\n",
    "                max_length=max_length,\n",
    "            )\n",
    "            toks = {k: v.to(device) for k, v in toks.items()}\n",
    "\n",
    "            # Lấy tất cả hidden_states thay vì chỉ last_hidden_state\n",
    "            outputs = model(**toks, output_hidden_states=True, return_dict=True)\n",
    "            hidden_states = outputs.hidden_states[-4:]        # lấy 4 lớp cuối\n",
    "            hidden = torch.stack(hidden_states, dim=0).mean(0)  # trung bình 4 lớp cuối  → [B, T, H] = [16, 128, 768]\n",
    "\n",
    "            # Mean pooling các token theo attention mask -> vector snentence\n",
    "            mask = toks[\"attention_mask\"].unsqueeze(-1)       # [B, T, 1]\n",
    "            sent = (hidden * mask).sum(1) / mask.sum(1).clamp(min=1)  # [B, H]\n",
    "\n",
    "            vecs.append(sent.cpu().numpy().astype(np.float32))\n",
    "\n",
    "    return np.vstack(vecs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e348ccab",
   "metadata": {},
   "source": [
    "**PhoBERT concat 4 last hidden**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6bec4da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_phobert_vectors_concat(texts, tokenizer, model, batch_size=16, max_length=128):\n",
    "    device = torch.device(\"cpu\")\n",
    "    model.to(device).eval()\n",
    "\n",
    "    # Bật lấy toàn bộ hidden states\n",
    "    model.config.output_hidden_states = True \n",
    "\n",
    "    vecs = []\n",
    "    with torch.inference_mode():\n",
    "        for i in range(0, len(texts), batch_size):\n",
    "            batch = texts[i:i+batch_size]\n",
    "            toks = tokenizer(\n",
    "                batch,\n",
    "                return_tensors=\"pt\",\n",
    "                padding=True,\n",
    "                truncation=True,\n",
    "                max_length=max_length,\n",
    "            )\n",
    "            toks = {k: v.to(device) for k, v in toks.items()}\n",
    "\n",
    "            outputs = model(**toks, output_hidden_states=True, return_dict=True)\n",
    "            hidden_states = outputs.hidden_states[-4:] \n",
    "            hidden = torch.cat(hidden_states, dim=-1) \n",
    "\n",
    "            mask = toks[\"attention_mask\"].unsqueeze(-1)\n",
    "            sent = (hidden * mask).sum(1) / mask.sum(1).clamp(min=1)\n",
    "\n",
    "            vecs.append(sent.cpu().numpy().astype(np.float32))\n",
    "\n",
    "    return np.vstack(vecs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487796c8",
   "metadata": {},
   "source": [
    "# Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729dc7ce",
   "metadata": {},
   "source": [
    "## PhoW2V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "95326e8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train phoW2V shape: (3000, 100)\n",
      "Dev phoW2V shape: (2000, 100)\n",
      "Test phoW2V shape: (600, 100)\n"
     ]
    }
   ],
   "source": [
    "X_train_phow2v = get_phow2v_vectors(X_train, w2v)\n",
    "X_dev_phow2v = get_phow2v_vectors(X_dev, w2v)\n",
    "X_test_phow2v = get_phow2v_vectors(X_test, w2v)\n",
    "\n",
    "print(\"Train phoW2V shape:\", X_train_phow2v.shape)\n",
    "print(\"Dev phoW2V shape:\", X_dev_phow2v.shape)\n",
    "print(\"Test phoW2V shape:\", X_test_phow2v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720cc8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_phow2v_train = pd.concat([pd.DataFrame(X_train_phow2v), y_train.reset_index(drop=True)], axis=1)\n",
    "# df_phow2v_train.to_csv(\"./VLSP2018_Hotel/Embedding/phoW2V_train.csv\", index=False)\n",
    "\n",
    "# df_phow2v_dev = pd.concat([pd.DataFrame(X_dev_phow2v), y_dev.reset_index(drop=True)], axis=1)\n",
    "# df_phow2v_dev.to_csv(\"./VLSP2018_Hotel/Embedding/phoW2V_dev.csv\", index=False)\n",
    "\n",
    "# df_phow2v_test = pd.concat([pd.DataFrame(X_test_phow2v), y_test.reset_index(drop=True)], axis=1)\n",
    "# df_phow2v_test.to_csv(\"./VLSP2018_Hotel/Embedding/phoW2V_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03d6649",
   "metadata": {},
   "source": [
    "## PhoBERT mean 4 last hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88873cf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train phoBERT shape: (3000, 768)\n",
      "Dev phoBERT shape: (2000, 768)\n",
      "Test phoBERT shape: (600, 768)\n"
     ]
    }
   ],
   "source": [
    "X_train_phoBERT = get_phobert_vectors(X_train, tokenizer, model, batch_size=16, max_length=128)\n",
    "X_dev_phoBERT = get_phobert_vectors(X_dev, tokenizer, model, batch_size=16, max_length=128)\n",
    "X_test_phoBERT = get_phobert_vectors(X_test, tokenizer, model, batch_size=16, max_length=128)\n",
    "\n",
    "print(\"Train phoBERT shape:\", X_train_phoBERT.shape)\n",
    "print(\"Dev phoBERT shape:\", X_dev_phoBERT.shape)\n",
    "print(\"Test phoBERT shape:\", X_test_phoBERT.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4026a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_phoBERT_train = pd.concat([pd.DataFrame(X_train_phoBERT), y_train.reset_index(drop=True)], axis=1)\n",
    "# df_phoBERT_train.to_csv(\"./VLSP2018_Hotel/Embedding/phoBERT_mean_train.csv\", index=False)\n",
    "\n",
    "# df_phoBERT_dev = pd.concat([pd.DataFrame(X_dev_phoBERT), y_dev.reset_index(drop=True)], axis=1)\n",
    "# df_phoBERT_dev.to_csv(\"./VLSP2018_Hotel/Embedding/phoBERT_mean_dev.csv\", index=False)\n",
    "\n",
    "# df_phoBERT_test = pd.concat([pd.DataFrame(X_test_phoBERT), y_test.reset_index(drop=True)], axis=1)\n",
    "# df_phoBERT_test.to_csv(\"./VLSP2018_Hotel/Embedding/phoBERT_mean_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e430b0",
   "metadata": {},
   "source": [
    "## PhoBERT concat 4 last hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62f43f02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train phoBERT shape: (3000, 3072)\n",
      "Dev phoBERT shape: (2000, 3072)\n",
      "Test phoBERT shape: (600, 3072)\n"
     ]
    }
   ],
   "source": [
    "X_train_phoBERT_concat = get_phobert_vectors_concat(X_train, tokenizer, model, batch_size=16, max_length=128)\n",
    "X_dev_phoBERT_concat = get_phobert_vectors_concat(X_dev, tokenizer, model, batch_size=16, max_length=128)\n",
    "X_test_phoBERT_concat = get_phobert_vectors_concat(X_test, tokenizer, model, batch_size=16, max_length=128)\n",
    "\n",
    "print(\"Train phoBERT shape:\", X_train_phoBERT_concat.shape)\n",
    "print(\"Dev phoBERT shape:\", X_dev_phoBERT_concat.shape)\n",
    "print(\"Test phoBERT shape:\", X_test_phoBERT_concat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b2d7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_phoBERT_concat_train = pd.concat([pd.DataFrame(X_train_phoBERT_concat), y_train.reset_index(drop=True)], axis=1)\n",
    "df_phoBERT_concat_train.to_csv(\"./VLSP2018_Hotel/Embedding/phoBERT_concat_train.csv\", index=False)\n",
    "\n",
    "df_phoBERT_concat_dev = pd.concat([pd.DataFrame(X_dev_phoBERT_concat), y_dev.reset_index(drop=True)], axis=1)\n",
    "df_phoBERT_concat_dev.to_csv(\"./VLSP2018_Hotel/Embedding/phoBERT_concat_dev.csv\", index=False)\n",
    "\n",
    "df_phoBERT_concat_test = pd.concat([pd.DataFrame(X_test_phoBERT_concat), y_test.reset_index(drop=True)], axis=1)\n",
    "df_phoBERT_concat_test.to_csv(\"./VLSP2018_Hotel/Embedding/phoBERT_concat_test.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
